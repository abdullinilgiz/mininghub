# Реализация пайплайна активного обучения
### Как использовать?
Заходим в файл `acitve/active_learning.py`. Тут есть несколько параметров:
```
FRAME_RATE = 24  # Каждый 24 кадр обрабатывается моделью
CONF_TRESHOLD = 0.8  # Порог на уверенность для детектируемых объектов
VIDEO_PATH = os.path.join(ROOT_DIR, 'data', '20sec_day.mp4')  # путь до видео
```
Выставив нужные параметры, мы можем использовать наш пайплайн для активного обучения.
```
python3 active_learning.py
```
### Как это работает?
Модель обрабатывает каждый 24 (зависит от `FRAME_RATE`) кадр. Если для всех детектируемых объектов на фрейме (кадре из видео) модель выдает значение уверенности в своем ответе больше чем 0.8 (зависит от `CONF_TRASHOLD`) то, избражение попадает в папку `confident`, в противном случае в папку `not_confident`.

### Что делать с изображениями, в которых модель не уверена?
Изображения и аннотации из папки `not_confident` импортируются в CVAT и доразмечаются. После чего их можно совместить с объектами из папки для уверенных предиктов.
Чтобы импоритовать файлы в CVAT их нужно привести к определенному виду. Я это сделал, файлы в необходимом для импорта виде вы можете найти по [ссылке](https://disk.yandex.ru/d/krmIDtVrHY8p7A).
Файл `train.txt` генерируется с помощью `active/get_train_text.py` и будет находится в той директории из которой вы данный файл запускали. Соответсвенно остается лишь заменять содержимое директории `obj_train_data`.